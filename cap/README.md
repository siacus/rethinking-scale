# Comparative Agenda Project
The data used to train the models are on Huggingface under [siacus/cap_pe_verified](https://huggingface.co/datasets/siacus/cap_pe_verified) and [cap_pe_verified-final-and-last](https://huggingface.co/datasets/siacus/cap_pe_verified-final-and-last)


The version of the fine-tuned models in GGUF format in both F16 and 4bit versions can be obtained from Hugginface: [llama-2-7b-cap_verified](https://huggingface.co/siacus/llama-2-7b-cap_verified) and
[llama-2-7b-cap_verified-final-and-last](https://huggingface.co/siacus/llama-2-7b-cap_verified-final-and-last)

# Fine-tuning
These python scripts perform the training for the LLAMA2 model
1. [finetune-L2-7B_verified.py](finetune-L2-7B_verified.py)
2. [finetune-L2-7B_verified-final-and-last.py](finetune-L2-7B_verified-final-and-last.py)

# Prompt used
The prompt for the fine-tuning is simple and only make use of the  parliamentary quesiton. The fine-tuned model is supposed to answer only a number in squared brackets as in the following example:

`<s>[INST] The next text is a question of a member of the European parliament. Classify the question according to only one of the policy areas below. Use only the policy area number taken from the list below. Do not explain your answer. Return only a python list containing the policy area number.:"1.Will the Commission estimate the cost to employers of implementing in full its agency workers directive proposal for each Member State? Will it express such a cost as a percentage of the total pay bill? 2.What estimate does the Commission make of any likely reduction in employment by Member State? 3.How is this proposal consistent with the Commissionâ€™s objective of increasing employment?" Analyze carefully the text and assign it to the most relevant policy area among those listed below. Do not explain your answer and return only a number. Policy area numbers: 1 = Macroeconomics 2 = Civil Rights, Minority Issues and Civil Liberties 3 = Health 4 = Agriculture and Fisheries 5 = Labour, employment and pensions 6 = Education 7 = Environment 8 = Energy 9 = Immigration 10 = Transportation 12 = Law and Crime 13 = Social welfare 14 = Regional and Urban issues and Planning 15 = Banking, finance and domestic commerce issues 16 = Defence 17 = Space, science, technology, and communications issues 18 = Foreign trade 19 = International affairs and foreign aid 20 = Governance and government 21 = Public Lands, Water Management and Territorial Issues 23 = Culture and media [/INST]. Answer = [5]. </s>`

# Inference
Run these python scripts to generate inference for the differet models. Each model produces a .csv file with the classification.

1. [test-L2-7B-CAP_verified.py](test-L2-7B-CAP_verified.py) : generates [classification_train-L2-7B-cap-verified-v2.csv](classification_train-L2-7B-cap-verified-v2.csv) and [classification_test-L2-7B-cap-verified-v2.csv](classification_test-L2-7B-cap-verified-v2.csv)
2. [test-L2-7B-CAP_verified-last-and-final.py](test-L2-7B-CAP_verified-last-and-final.py) : generates [classification_train-L2-7B-cap-verified-last-and-final.csv](classification_train-L2-7B-cap-verified-last-and-final.csv) and [classification_test-L2-7B-cap-verified-last-and-final.csv](classification_test-L2-7B-cap-verified-last-and-final.csv)

# Summary statistics
Summary statistics can be obtained executing this R script: [summaryStat.R](summaryStat.R)

