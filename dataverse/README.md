# Dataverse
The data used to train the model are on Huggingface under [siacus/dv_subject](https://huggingface.co/datasets/siacus/dv_subject)

The `small-dv` version of the fine-tuned model works on a training-set of 5,000 randomly sampled data.

The large version works on the whole 76.1K training records.

The test set is of size 32.6K rows.

The two versions of the fine-tuned models in GGUF format in both F16 and 4bit versions can be obtained from Hugginface: [llama-2-7b-small-dv](https://huggingface.co/siacus/llama-2-7b-small-dv) and [llama-2-7b-dv](https://huggingface.co/siacus/llama-2-7b-dv)

